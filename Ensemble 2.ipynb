{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging algorithms\n",
    "* bootstrap agreggation or bagging involves taking multiple sample from your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bagged Decision tree\n",
    "* bagging is always contain same root note and feature so alwys gives same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as nnp\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=\"F:\\\\Afitech PPML Datasets\\\\diabetes.csv\"\n",
    "\n",
    "df=pd.read_csv(file)\n",
    "array=df.values\n",
    "x=array[:,0:8]\n",
    "y=array[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.770745044429255\n"
     ]
    }
   ],
   "source": [
    "seed=7\n",
    "kfold=model_selection.KFold(n_splits=10, random_state=seed)\n",
    "cart=DecisionTreeClassifier()\n",
    "num_trees=100\n",
    "model=BaggingClassifier(base_estimator=cart,n_estimators=num_trees,random_state=seed) # cart is applying different type of algo\n",
    "result=model_selection.cross_val_score(model,x,y,cv=kfold)\n",
    "print(result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as nnp\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=\"F:\\\\Afitech PPML Datasets\\\\diabetes.csv\"\n",
    "\n",
    "df=pd.read_csv(file)\n",
    "array=df.values\n",
    "x=array[:,0:8]\n",
    "y=array[:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7577751196172249\n"
     ]
    }
   ],
   "source": [
    "seed=7\n",
    "max_features=3\n",
    "kfold=model_selection.KFold(n_splits=10, random_state=seed)\n",
    "\n",
    "num_trees=100\n",
    "model=RandomForestClassifier(n_estimators=num_trees,max_features=max_features) \n",
    "result=model_selection.cross_val_score(model,x,y,cv=kfold)\n",
    "print(result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra trees classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7629186602870812\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as nnp\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "file=\"F:\\\\Afitech PPML Datasets\\\\diabetes.csv\"\n",
    "\n",
    "df=pd.read_csv(file)\n",
    "array=df.values\n",
    "x=array[:,0:8]\n",
    "y=array[:,8]\n",
    "\n",
    "seed=7\n",
    "max_features=7\n",
    "kfold=model_selection.KFold(n_splits=10, random_state=seed)\n",
    "\n",
    "num_trees=100\n",
    "model=ExtraTreesClassifier(n_estimators=num_trees,max_features=max_features) \n",
    "result=model_selection.cross_val_score(model,x,y,cv=kfold)\n",
    "print(result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting algorithms\n",
    "* one layer decision tree is called stumps\n",
    "* type of boosting algo\n",
    "    * AdaBoost\n",
    "    * Stochastic gradient Boosting\n",
    "* In boosting Decision data set only traing data and testing data is own Decision entire data\n",
    "* Here traing data is less then testing data set\n",
    "* entire whole data is useing testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.760457963089542\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as nnp\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "file=\"F:\\\\Afitech PPML Datasets\\\\diabetes.csv\"\n",
    "\n",
    "df=pd.read_csv(file)\n",
    "array=df.values\n",
    "x=array[:,0:8]\n",
    "y=array[:,8]\n",
    "\n",
    "seed=7\n",
    "max_features=7\n",
    "kfold=model_selection.KFold(n_splits=10, random_state=seed)\n",
    "\n",
    "num_trees=30\n",
    "model=AdaBoostClassifier(n_estimators=num_trees,random_state=seed) \n",
    "result=model_selection.cross_val_score(model,x,y,cv=kfold)\n",
    "print(result.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stochostic Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7733253588516746\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "file=\"F:\\\\Afitech PPML Datasets\\\\diabetes.csv\"\n",
    "\n",
    "df=pd.read_csv(file)\n",
    "array=df.values\n",
    "x=array[:,0:8]\n",
    "y=array[:,8]\n",
    "\n",
    "seed=7\n",
    "max_features=7\n",
    "kfold=model_selection.KFold(n_splits=10, random_state=seed)\n",
    "\n",
    "num_trees=30\n",
    "model=GradientBoostingClassifier(n_estimators=num_trees,random_state=seed) \n",
    "result=model_selection.cross_val_score(model,x,y,cv=kfold)\n",
    "print(result.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### voting ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import VotingClassifier#, RandomForestClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=\"F:\\\\Afitech PPML Datasets\\\\diabetes.csv\"\n",
    "\n",
    "df=pd.read_csv(file)\n",
    "array=df.values\n",
    "x=array[:,0:8]\n",
    "y=array[:,8]\n",
    "\n",
    "seed=7\n",
    "\n",
    "kfold=model_selection.KFold(n_splits=10, random_state=seed)\n",
    "estimators=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=LogisticRegression()\n",
    "estimators.append(('logistic',model1))\n",
    "\n",
    "model2=DecisionTreeClassifier()\n",
    "estimators.append(('cart',model2))\n",
    "\n",
    "model3=SVC()\n",
    "estimators.append(('svm',model3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ravi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ravi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Ravi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ravi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Ravi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ravi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Ravi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ravi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Ravi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ravi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Ravi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ravi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Ravi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ravi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Ravi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ravi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Ravi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ravi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\Ravi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Ravi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "ensemble=VotingClassifier(estimators)\n",
    "results=model_selection.cross_val_score(ensemble,x,y,cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method mean of numpy.ndarray object at 0x0000015486410530>\n",
      "[0.64935065 0.79220779 0.72727273 0.62337662 0.74025974 0.72727273\n",
      " 0.83116883 0.81818182 0.69736842 0.69736842]\n"
     ]
    }
   ],
   "source": [
    "print(results.mean)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
